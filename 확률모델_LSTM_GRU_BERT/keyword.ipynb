{"cells":[{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["f19036e5f7db4c91866058ffca31b1d9","506b645201bc481c9beb45031ba9e321","b2d08f3747674164a9ff1e7a75440ae1","51d0ef732ad04e5cace2745bb43f13a9","d4c1a78fb4d44209857b11d02e1d8b3c","d929869bda554a8c9c31868e5260c754","9a414718daeb422c89b3584c6728cb36","7e24fe79f35e48c7bb35b4746ec32f9a","b66c4efe06034a6699ce9e80e9cfed37","9b04a8e496e84a19bbfa5b20b64ae100","109419b02b6a4ed5bc61bc0de8b699bb","7117bf4cde7f42afa2e2b1dd90fd1f05","7e5d7083873941afaeb40394b1d60f8b","12356a03dd034bd6b94cd612137c862c","a10481cdc6ec4167bdd4d2d89fc991f6","4d9e1affa4004a78a2c1cb281e43214c","e6b4ff965b0a4ad2aeea893ca4a1c141","86a014f0261e442d8ee1e5c5f84c523f","a2af58d9ad08443a82619d199f228e30","7f9ca7d348814f69a5e39095e5e9563f","6776ddbff7324c709aa0b648c43ef07d","034be1968a6048a3a04cee4c7fb0c549"]},"id":"H-yptkfUczRZ","outputId":"6868a459-e68b-446f-f2ad-f677d8300180","executionInfo":{"status":"ok","timestamp":1755312292012,"user_tz":-540,"elapsed":493687,"user":{"displayName":"jiwon song","userId":"09013595362968296143"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","[INFO] device: cuda\n"]},{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/4131 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f19036e5f7db4c91866058ffca31b1d9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/1033 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7117bf4cde7f42afa2e2b1dd90fd1f05"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["[INFO] Train size: 4131, Test size: 1033\n","[INFO] Label dist (train):\n"," label\n","1    2805\n","0    1326\n","Name: count, dtype: int64\n","[INFO] Label dist (test):\n"," label\n","1    702\n","0    331\n","Name: count, dtype: int64\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["[INFO] transformers version: 4.55.2\n","[INFO] TrainingArguments accepted keys -> ['output_dir', 'save_strategy', 'learning_rate', 'per_device_train_batch_size', 'per_device_eval_batch_size', 'num_train_epochs', 'weight_decay', 'logging_steps', 'load_best_model_at_end', 'fp16', 'warmup_ratio', 'report_to', 'do_eval', 'eval_steps', 'save_steps', 'logging_dir']\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='1034' max='1034' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1034/1034 01:11, Epoch 2/2]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>50</td>\n","      <td>0.552000</td>\n","    </tr>\n","    <tr>\n","      <td>100</td>\n","      <td>0.158300</td>\n","    </tr>\n","    <tr>\n","      <td>150</td>\n","      <td>0.245100</td>\n","    </tr>\n","    <tr>\n","      <td>200</td>\n","      <td>0.126200</td>\n","    </tr>\n","    <tr>\n","      <td>250</td>\n","      <td>0.214800</td>\n","    </tr>\n","    <tr>\n","      <td>300</td>\n","      <td>0.161300</td>\n","    </tr>\n","    <tr>\n","      <td>350</td>\n","      <td>0.108300</td>\n","    </tr>\n","    <tr>\n","      <td>400</td>\n","      <td>0.098400</td>\n","    </tr>\n","    <tr>\n","      <td>450</td>\n","      <td>0.074600</td>\n","    </tr>\n","    <tr>\n","      <td>500</td>\n","      <td>0.048500</td>\n","    </tr>\n","    <tr>\n","      <td>550</td>\n","      <td>0.119500</td>\n","    </tr>\n","    <tr>\n","      <td>600</td>\n","      <td>0.090600</td>\n","    </tr>\n","    <tr>\n","      <td>650</td>\n","      <td>0.077500</td>\n","    </tr>\n","    <tr>\n","      <td>700</td>\n","      <td>0.036100</td>\n","    </tr>\n","    <tr>\n","      <td>750</td>\n","      <td>0.049500</td>\n","    </tr>\n","    <tr>\n","      <td>800</td>\n","      <td>0.027900</td>\n","    </tr>\n","    <tr>\n","      <td>850</td>\n","      <td>0.031000</td>\n","    </tr>\n","    <tr>\n","      <td>900</td>\n","      <td>0.013900</td>\n","    </tr>\n","    <tr>\n","      <td>950</td>\n","      <td>0.036300</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>0.017300</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["[INFO] Fitted Temperature: 1.3158\n","[INFO] Classification report (calibrated p):\n","              precision    recall  f1-score   support\n","\n","          정상     0.9940    0.9940    0.9940       331\n","       보이스피싱     0.9972    0.9972    0.9972       702\n","\n","    accuracy                         0.9961      1033\n","   macro avg     0.9956    0.9956    0.9956      1033\n","weighted avg     0.9961    0.9961    0.9961      1033\n","\n","✅ '/content/drive/MyDrive/KDH/dataset/prediction_with_keywords_v2_rollout_top5_thr70.csv' 저장 완료 (rollout only, top_k=5, thr=0.7, suff≥0.55, comp≥0.08)\n"]}],"source":["# ===============================\n","# 0) 라이브러리 로딩 & 환경 고정\n","# ===============================\n","import os\n","import re\n","import random\n","import numpy as np\n","import pandas as pd\n","import torch\n","\n","from datasets import Dataset\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import (\n","    accuracy_score,\n","    precision_recall_fscore_support,\n","    classification_report,\n","    confusion_matrix,\n","    f1_score,\n",")\n","\n","from transformers import (\n","    AutoTokenizer,\n","    RobertaForSequenceClassification,\n","    Trainer,\n","    TrainingArguments,\n","    DataCollatorWithPadding,\n","    set_seed,\n",")\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# 재현성 고정\n","SEED = 42\n","random.seed(SEED)\n","np.random.seed(SEED)\n","torch.manual_seed(SEED)\n","if torch.cuda.is_available():\n","    torch.cuda.manual_seed_all(SEED)\n","set_seed(SEED)\n","\n","device = 0 if torch.cuda.is_available() else -1\n","print(f\"[INFO] device: {'cuda' if device == 0 else 'cpu'}\")\n","\n","# ===============================\n","# 1) 데이터 로딩 & 전처리\n","# ===============================\n","CSV_PATH = \"/content/drive/MyDrive/KDH/dataset/cleaned_datasets (0814)_utf8.csv\"\n","df = pd.read_csv(CSV_PATH)\n","df[\"label\"] = df[\"label\"].astype(int)\n","\n","def clean_text(text: str) -> str:\n","    # 연속 마침표 → 하나로\n","    text = re.sub(r\"\\.{2,}\", \".\", text)\n","    # 영어/숫자와 한글 사이 공백\n","    text = re.sub(r\"([A-Za-z0-9])([가-힣])\", r\"\\1 \\2\", text)\n","    text = re.sub(r\"([가-힣])([A-Za-z0-9])\", r\"\\1 \\2\", text)\n","    # 특수문자 제거 (.,!?는 유지)\n","    text = re.sub(r\"[^\\w\\s.,!?]\", \"\", text)\n","    # 다중 공백 제거\n","    text = re.sub(r\"\\s+\", \" \", text).strip()\n","    return text\n","\n","X_train, X_test, y_train, y_test = train_test_split(\n","    df[\"text\"].apply(clean_text),\n","    df[\"label\"],\n","    test_size=0.2,\n","    stratify=df[\"label\"],\n","    random_state=SEED,\n",")\n","\n","# ===============================\n","# 2) 토크나이저/데이터셋 (동적 패딩)\n","# ===============================\n","MODEL_NAME = \"klue/roberta-base\"\n","tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n","tokenizer.model_max_length = 512  # 안전한 최대 길이\n","\n","def tokenize_fn(batch):\n","    # padding은 collator가 담당 → 여기선 truncation만\n","    return tokenizer(batch[\"text\"], truncation=True)\n","\n","# Hugging Face Dataset 생성 (라벨 키는 'labels'로 통일!)\n","train_ds = Dataset.from_dict({\"text\": X_train.tolist(), \"labels\": y_train.tolist()})\n","test_ds  = Dataset.from_dict({\"text\": X_test.tolist(),  \"labels\": y_test .tolist()})\n","\n","# 토큰화 적용\n","train_ds = train_ds.map(tokenize_fn, batched=True, remove_columns=[\"text\"])\n","test_ds  = test_ds.map(tokenize_fn, batched=True, remove_columns=[\"text\"])\n","\n","# 포맷 지정\n","train_ds.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n","test_ds.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n","\n","# 동적 패딩 collator\n","data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n","\n","print(f\"[INFO] Train size: {len(train_ds)}, Test size: {len(test_ds)}\")\n","print(\"[INFO] Label dist (train):\\n\", pd.Series(y_train).value_counts())\n","print(\"[INFO] Label dist (test):\\n\",  pd.Series(y_test).value_counts())\n","\n","# ===============================\n","# ===============================\n","# 3) 모델 로딩 (warning 제거: eager attention 명시)\n","# ===============================\n","from transformers import AutoConfig\n","\n","try:\n","    model = RobertaForSequenceClassification.from_pretrained(\n","        MODEL_NAME,\n","        num_labels=2,\n","        attn_implementation=\"eager\",  # output_attentions=True와 함께 안전\n","    )\n","except TypeError:\n","    # 구버전 호환: config에 주입\n","    cfg = AutoConfig.from_pretrained(MODEL_NAME)\n","    setattr(cfg, \"attn_implementation\", \"eager\")\n","    model = RobertaForSequenceClassification.from_pretrained(\n","        MODEL_NAME,\n","        config=cfg,\n","        num_labels=2,\n","    )\n","\n","# id2label/label2id 세팅(해석/로깅 편의)\n","id2label = {0: \"정상\", 1: \"보이스피싱\"}\n","label2id = {\"정상\": 0, \"보이스피싱\": 1}\n","model.config.id2label = id2label\n","model.config.label2id = label2id\n","\n","# id2label/label2id 세팅(해석/로깅 편의)\n","id2label = {0: \"정상\", 1: \"보이스피싱\"}\n","label2id = {\"정상\": 0, \"보이스피싱\": 1}\n","model.config.id2label = id2label\n","model.config.label2id = label2id\n","\n","# ===============================\n","# ===============================\n","# ===============================\n","# # ===============================\n","# 4) 평가지표 & 학습 설정 — 버전 호환 안전 패치\n","# ===============================\n","import transformers, inspect\n","\n","def compute_metrics(eval_pred):\n","    logits, labels = eval_pred\n","    preds = logits.argmax(axis=-1)\n","    p, r, f1, _ = precision_recall_fscore_support(labels, preds, average=\"binary\", pos_label=1)\n","    acc = accuracy_score(labels, preds)\n","    return {\"accuracy\": acc, \"precision\": p, \"recall\": r, \"f1\": f1}\n","\n","_desired_kwargs = dict(\n","    output_dir=\"./klue-roberta-voice\",\n","    evaluation_strategy=\"epoch\",   # 신버전용\n","    save_strategy=\"epoch\",         # 신버전용\n","    learning_rate=5e-5,\n","    per_device_train_batch_size=8,\n","    per_device_eval_batch_size=8,\n","    num_train_epochs=2,\n","    weight_decay=0.01,\n","    logging_steps=50,\n","    load_best_model_at_end=True,   # 전략 불일치/구버전이면 자동 끔\n","    metric_for_best_model=\"f1\",\n","    greater_is_better=True,\n","    fp16=torch.cuda.is_available(),\n","    warmup_ratio=0.1,\n","    report_to=\"none\",\n","    # 구버전 대체(step 기반)\n","    do_eval=True,\n","    eval_steps=500,\n","    save_steps=500,\n","    logging_dir=\"./logs\",\n","    evaluate_during_training=True,\n",")\n","\n","sig_params = set(inspect.signature(TrainingArguments.__init__).parameters.keys()) - {\"self\"}\n","safe_kwargs = {k: v for k, v in _desired_kwargs.items() if k in sig_params}\n","\n","# evaluation_strategy 미지원 → 구버전: step 기반으로, load_best는 끔\n","if \"evaluation_strategy\" not in sig_params:\n","    for k in (\"eval_steps\", \"save_steps\", \"do_eval\"):\n","        if k in _desired_kwargs and k in sig_params:\n","            safe_kwargs[k] = _desired_kwargs[k]\n","    if \"load_best_model_at_end\" in sig_params:\n","        safe_kwargs[\"load_best_model_at_end\"] = False\n","    safe_kwargs.pop(\"metric_for_best_model\", None)\n","    safe_kwargs.pop(\"greater_is_better\", None)\n","\n","# load_best가 켜졌는데 전략 키가 없으면 안전하게 끔\n","if \"load_best_model_at_end\" in sig_params and safe_kwargs.get(\"load_best_model_at_end\", False):\n","    if (\"evaluation_strategy\" not in sig_params) or (\"save_strategy\" not in sig_params):\n","        safe_kwargs[\"load_best_model_at_end\"] = False\n","\n","training_args = TrainingArguments(**safe_kwargs)\n","\n","print(\"[INFO] transformers version:\", getattr(transformers, \"__version__\", \"unknown\"))\n","print(\"[INFO] TrainingArguments accepted keys ->\", list(safe_kwargs.keys()))\n","\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=train_ds,\n","    eval_dataset=test_ds,\n","    data_collator=data_collator,\n","    compute_metrics=compute_metrics,\n",")\n","\n","\n","# ===============================\n","# 5) 학습\n","# ===============================\n","trainer.train()\n","\n","# ===============================\n","# 6) 예측 + 확률 보정(Temperature Scaling)\n","# ===============================\n","model.eval()\n","pred_output = trainer.predict(test_ds)\n","logits = pred_output.predictions        # (N, 2)\n","y_true = pred_output.label_ids\n","\n","# ----- Temperature Scaling -----\n","class _TempScale(torch.nn.Module):\n","    def __init__(self, init_T: float = 1.0):\n","        super().__init__()\n","        self.T = torch.nn.Parameter(torch.ones(1) * init_T)\n","\n","    def forward(self, logits_tensor: torch.Tensor) -> torch.Tensor:\n","        # logits / T\n","        return logits_tensor / self.T.unsqueeze(1)\n","\n","def fit_temperature(logits_np: np.ndarray, labels_np: np.ndarray, max_iter=50, lr=0.01) -> float:\n","    \"\"\"\n","    간단한 LBFGS로 NLL 최소화하여 온도 T 학습\n","    \"\"\"\n","    logits_t = torch.tensor(logits_np, dtype=torch.float32)\n","    labels_t = torch.tensor(labels_np, dtype=torch.long)\n","\n","    scaler = _TempScale()\n","    nll = torch.nn.CrossEntropyLoss()\n","    optimizer = torch.optim.LBFGS([scaler.T], lr=lr, max_iter=max_iter, line_search_fn=\"strong_wolfe\")\n","\n","    def closure():\n","        optimizer.zero_grad()\n","        loss = nll(scaler(logits_t), labels_t)\n","        loss.backward()\n","        return loss\n","\n","    optimizer.step(closure)\n","    T_value = float(scaler.T.detach().cpu().item())\n","    print(f\"[INFO] Fitted Temperature: {T_value:.4f}\")\n","    return max(T_value, 1e-3)\n","\n","# T 학습(실무에선 별도 검증셋 권장)\n","T = fit_temperature(logits, y_true)\n","logits_cal = logits / T\n","\n","probs_full = torch.softmax(torch.tensor(logits_cal), dim=1).numpy()\n","p1_cal = probs_full[:, 1]   # 보이스피싱 calibrated 확률\n","\n","THRESH = 0.7\n","y_pred = (p1_cal >= THRESH).astype(int)\n","\n","print(\"[INFO] Classification report (calibrated p):\")\n","print(classification_report(y_true, y_pred, target_names=[\"정상\", \"보이스피싱\"], digits=4))\n","\n","# ===============================\n","# ===============================\n","# (필수) 품사 태깅 도구 설치/로딩\n","# ===============================\n","!pip -q install konlpy==0.6.0\n","from konlpy.tag import Okt\n","okt = Okt()\n","\n","# 원한다면 여기서 불용어(명사지만 제외하고 싶은 단어) 추가하세요\n","STOP_NOUNS = {\n","    \"쪽\", \"부분\", \"경우\", \"상황\", \"발생\", \"문제\", \"고객\", \"안내\", \"확인\", \"처리\",\n","    \"연락\", \"상담\", \"번호\", \"내용\", \"시스템\", \"담당\", \"사용자\", \"현재\", \"오늘\",\n","}\n","# ===============================\n","# 7) 증거 윈도우 + Δp1(마스킹 영향도) 기반 키워드 — ROLLOUT ONLY\n","# ===============================\n","import re\n","import torch\n","from torch.nn.functional import softmax\n","import numpy as np\n","\n","# 문장 분할 & 윈도우 선택 — 가변 길이 look-behind 제거\n","_SENT_SPLIT = re.compile(r'(?:(?<=[.?!])|(?<=[가-힣]\\))|(?<=요))\\s+')\n","\n","def split_sentences_ko(text: str):\n","    sents = [s.strip() for s in _SENT_SPLIT.split(text) if s and s.strip()]\n","    return sents if sents else [text.strip()]\n","\n","\n","def join_window(sents, i, radius=1, max_chars=400):\n","    left = max(0, i - radius)\n","    right = min(len(sents), i + radius + 1)\n","    cand = \" \".join(sents[left:right])\n","    return cand if len(cand) <= max_chars else cand[:max_chars]\n","\n","@torch.no_grad()\n","def p1_text(model, tokenizer, text: str):\n","    enc = tokenizer(text, return_tensors=\"pt\", truncation=True,\n","                    max_length=getattr(tokenizer, \"model_max_length\", 512),\n","                    padding=False).to(model.device)\n","    logits = model(**enc).logits\n","    return float(softmax(logits, dim=-1)[0, 1].item())\n","\n","def pick_best_window(text: str, model, tokenizer, radius=1, max_chars=400):\n","    sents = split_sentences_ko(text)\n","    if len(sents) == 1:\n","        return sents[0], [sents[0]]\n","    best_p, best_w = -1.0, None\n","    for i in range(len(sents)):\n","        w = join_window(sents, i, radius=radius, max_chars=max_chars)\n","        p = p1_text(model, tokenizer, w)\n","        if p > best_p:\n","            best_p, best_w = p, w\n","    return best_w, sents\n","\n","@torch.no_grad()\n","def _token_scores_rollout(model, tokenizer, text, head_reduction=\"mean\"):\n","    enc = tokenizer(text, return_tensors=\"pt\", truncation=True,\n","                    max_length=getattr(tokenizer, \"model_max_length\", 512),\n","                    padding=False).to(model.device)\n","    out = model(**enc, output_attentions=True)\n","\n","    mats=[]\n","    for A in out.attentions:                 # tuple(L) of (B,H,S,S)\n","        A = A.mean(dim=1) if head_reduction==\"mean\" else A.max(dim=1).values\n","        A = A[0]\n","        A = A + torch.eye(A.size(-1), device=A.device)   # residual\n","        A = A / (A.sum(dim=-1, keepdim=True)+1e-6)\n","        mats.append(A)\n","    R = mats[0]\n","    for k in range(1,len(mats)):\n","        R = R @ mats[k]\n","    scores = R[0]                            # CLS -> tokens\n","    ids = enc[\"input_ids\"][0].cpu()\n","    tokens = tokenizer.convert_ids_to_tokens(ids)\n","    return tokens, scores.detach().cpu().numpy(), enc\n","\n","def _merge_subwords(tokens, scores, specials):\n","    words, word_scores, spans = [], [], []\n","    cur_w, cur_s, cur_span = \"\", 0.0, []\n","    def flush():\n","        nonlocal cur_w, cur_s, cur_span\n","        if cur_w != \"\":\n","            words.append(cur_w.replace(\"▁\",\"\"))\n","            word_scores.append(cur_s)\n","            spans.append(cur_span[:])\n","            cur_w, cur_s, cur_span = \"\", 0.0, []\n","    keep_idx = [i for i,t in enumerate(tokens) if t not in specials]\n","    toks = [tokens[i] for i in keep_idx]\n","    scs  = [scores[i] for i in keep_idx]\n","    for i,(t,s) in enumerate(zip(toks, scs)):\n","        if t.startswith(\"▁\") or not t.startswith(\"##\"):\n","            flush(); cur_w = t; cur_s = float(s); cur_span=[i]\n","        else:\n","            cur_w += t[2:]; cur_s += float(s); cur_span.append(i)\n","    flush()\n","    return keep_idx, toks, np.array(scs), words, np.array(word_scores), spans\n","\n","@torch.no_grad()\n","def extract_keywords_with_delta_rollout(\n","    text, model, tokenizer, head_reduction=\"mean\",\n","    top_k=5, prelim_k=20, min_delta=0.03\n","):\n","    tokens, tok_scores, enc = _token_scores_rollout(model, tokenizer, text, head_reduction)\n","    specials = set(tokenizer.all_special_tokens) | {\"<s>\",\"</s>\",\"<pad>\"}\n","    keep_idx, kept_tokens, kept_scores, words, word_scores, spans = _merge_subwords(tokens, tok_scores, specials)\n","    if len(words)==0 or word_scores.sum()==0:\n","        base_p = p1_text(model, tokenizer, text)\n","        return [], base_p\n","\n","    # 길이 보정 후 후보 확장\n","    word_scores = word_scores * len(kept_tokens)\n","    idx_pre = word_scores.argsort()[::-1][:max(prelim_k, top_k*4)]\n","    base_p = p1_text(model, tokenizer, text)\n","\n","    mask_id = tokenizer.mask_token_id\n","    ids0 = enc[\"input_ids\"][0].clone()\n","    results=[]\n","    for j in idx_pre:\n","        orig_span = [keep_idx[s] for s in spans[j]]\n","        ids_m = ids0.clone()\n","        for pos in orig_span:\n","            ids_m[pos] = mask_id\n","        enc_m = {\"input_ids\": ids_m.unsqueeze(0).to(model.device),\n","                 \"attention_mask\": enc[\"attention_mask\"]}\n","        p1_m = float(softmax(model(**enc_m).logits, dim=-1)[0,1].item())\n","        delta = base_p - p1_m\n","        if delta >= min_delta:\n","            results.append({\"word\": words[j], \"delta\": float(delta), \"attn\": float(word_scores[j])})\n","\n","    results.sort(key=lambda x: (-x[\"delta\"], -x[\"attn\"], -len(x[\"word\"])))\n","    return results[:top_k], base_p\n","\n","@torch.no_grad()\n","def evidential_check_rollout(text, model, tokenizer,\n","                             top_k=5, min_delta=0.03, suff_th=0.55, comp_th=0.08):\n","    kw, base_p = extract_keywords_with_delta_rollout(\n","        text, model, tokenizer, top_k=top_k,\n","        prelim_k=max(20, top_k*4), min_delta=min_delta\n","    )\n","    if base_p < suff_th or not kw:\n","        return False, kw, base_p, 0.0\n","\n","    masked = text\n","    for w in sorted([k[\"word\"] for k in kw], key=len, reverse=True):\n","        masked = re.sub(re.escape(w), tokenizer.mask_token, masked)\n","    p1_m = p1_text(model, tokenizer, masked)\n","    comp = base_p - p1_m\n","    return comp >= comp_th, kw, base_p, comp\n","\n","def get_keywords_from_text_rollout(\n","    text, model, tokenizer, radius=1, max_chars=400,\n","    top_k=5, min_delta=0.03, suff_th=0.55, comp_th=0.08\n","):\n","    win, _ = pick_best_window(text, model, tokenizer, radius=radius, max_chars=max_chars)\n","    ok, kw, base_p, comp = evidential_check_rollout(\n","        win, model, tokenizer, top_k=top_k,\n","        min_delta=min_delta, suff_th=suff_th, comp_th=comp_th\n","    )\n","    if not ok:\n","        return {\"window\": win, \"base_p\": base_p, \"comp\": comp, \"keywords\": []}\n","    return {\"window\": win, \"base_p\": base_p, \"comp\": comp, \"keywords\": kw}\n","\n","\n","# ===============================\n","# 8) 결과 CSV 저장 (명사 top_k=3, 전역 0~100점)\n","# ===============================\n","# ===============================\n","# 8) 결과 저장 — ROLLOUT ONLY\n","# ===============================\n","TOP_K   = 5\n","THRESH  = 0.7        # calibrated 확률 임계값(위에서 쓰던 값 그대로)\n","SUFF_TH = 0.55       # 윈도우 충분성\n","COMP_TH = 0.08       # 포괄성(동시 마스킹 Δ)\n","MIN_DELTA = 0.03     # 키워드 개별 Δ 임계값\n","\n","def save_predictions_with_evidence_rollout(\n","    top_k=TOP_K, thresh=THRESH,\n","    suff_th=SUFF_TH, comp_th=COMP_TH, min_delta=MIN_DELTA,\n","    out_prefix=\"prediction_with_keywords_v2_rollout\"\n","):\n","    rows=[]\n","    model.eval()\n","    for i in range(len(X_test)):\n","        sent = X_test.iloc[i]\n","        label_true = int(y_true[i])\n","        prob1 = float(p1_cal[i])              # temperature scaling된 최종 확률\n","        label_pred = int(prob1 >= thresh)\n","\n","        info = get_keywords_from_text_rollout(\n","            sent, model, tokenizer,\n","            radius=1, max_chars=400,\n","            top_k=top_k, min_delta=min_delta,\n","            suff_th=suff_th, comp_th=comp_th\n","        )\n","        kw_str   = \", \".join([f\"{k['word']}\" for k in info[\"keywords\"]]) if info[\"keywords\"] else \"\"\n","        kw_delta = \"; \".join([f\"{k['word']}:{k['delta']:.3f}\" for k in info[\"keywords\"]]) if info[\"keywords\"] else \"\"\n","\n","        rows.append({\n","            \"문장(원본)\": sent,\n","            \"실제 라벨\": label_true,\n","            \"예측 라벨\": label_pred,\n","            \"보이스피싱 확률(p1_cal)\": prob1,\n","            \"증거윈도우\": info[\"window\"],\n","            \"윈도우 p(보피)\": info[\"base_p\"],\n","            \"윈도우 포괄성Δ\": info[\"comp\"],\n","            \"근거 키워드(Rollout)\": kw_str,\n","            \"키워드Δ(각)\": kw_delta,\n","            \"임계값(최종)\": thresh,\n","        })\n","\n","    out_path = f\"/content/drive/MyDrive/KDH/dataset/{out_prefix}_top{top_k}_thr{int(thresh*100)}.csv\"\n","    pd.DataFrame(rows).to_csv(out_path, index=False, encoding=\"utf-8-sig\")\n","    print(f\"✅ '{out_path}' 저장 완료 (rollout only, top_k={top_k}, thr={thresh}, suff≥{suff_th}, comp≥{comp_th})\")\n","\n","# 실행\n","save_predictions_with_evidence_rollout()\n","\n","\n"]},{"cell_type":"code","source":["!pip -q install --upgrade \"transformers>=4.42\" \"datasets>=2.19\" \"accelerate>=0.33\"\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"V9Xm32PipgO1","executionInfo":{"status":"ok","timestamp":1755310575955,"user_tz":-540,"elapsed":74949,"user":{"displayName":"jiwon song","userId":"09013595362968296143"}},"outputId":"96d4baed-94f5-4995-e0fc-52c625437776"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m126.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m100.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m56.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m44.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m103.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"A100","machine_shape":"hm","provenance":[],"authorship_tag":"ABX9TyOP0+xai+pkzZgiMBn5KwoH"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"f19036e5f7db4c91866058ffca31b1d9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_506b645201bc481c9beb45031ba9e321","IPY_MODEL_b2d08f3747674164a9ff1e7a75440ae1","IPY_MODEL_51d0ef732ad04e5cace2745bb43f13a9"],"layout":"IPY_MODEL_d4c1a78fb4d44209857b11d02e1d8b3c"}},"506b645201bc481c9beb45031ba9e321":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d929869bda554a8c9c31868e5260c754","placeholder":"​","style":"IPY_MODEL_9a414718daeb422c89b3584c6728cb36","value":"Map: 100%"}},"b2d08f3747674164a9ff1e7a75440ae1":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7e24fe79f35e48c7bb35b4746ec32f9a","max":4131,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b66c4efe06034a6699ce9e80e9cfed37","value":4131}},"51d0ef732ad04e5cace2745bb43f13a9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9b04a8e496e84a19bbfa5b20b64ae100","placeholder":"​","style":"IPY_MODEL_109419b02b6a4ed5bc61bc0de8b699bb","value":" 4131/4131 [00:00&lt;00:00, 8133.97 examples/s]"}},"d4c1a78fb4d44209857b11d02e1d8b3c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d929869bda554a8c9c31868e5260c754":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9a414718daeb422c89b3584c6728cb36":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7e24fe79f35e48c7bb35b4746ec32f9a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b66c4efe06034a6699ce9e80e9cfed37":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9b04a8e496e84a19bbfa5b20b64ae100":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"109419b02b6a4ed5bc61bc0de8b699bb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7117bf4cde7f42afa2e2b1dd90fd1f05":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7e5d7083873941afaeb40394b1d60f8b","IPY_MODEL_12356a03dd034bd6b94cd612137c862c","IPY_MODEL_a10481cdc6ec4167bdd4d2d89fc991f6"],"layout":"IPY_MODEL_4d9e1affa4004a78a2c1cb281e43214c"}},"7e5d7083873941afaeb40394b1d60f8b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e6b4ff965b0a4ad2aeea893ca4a1c141","placeholder":"​","style":"IPY_MODEL_86a014f0261e442d8ee1e5c5f84c523f","value":"Map: 100%"}},"12356a03dd034bd6b94cd612137c862c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a2af58d9ad08443a82619d199f228e30","max":1033,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7f9ca7d348814f69a5e39095e5e9563f","value":1033}},"a10481cdc6ec4167bdd4d2d89fc991f6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6776ddbff7324c709aa0b648c43ef07d","placeholder":"​","style":"IPY_MODEL_034be1968a6048a3a04cee4c7fb0c549","value":" 1033/1033 [00:00&lt;00:00, 8040.23 examples/s]"}},"4d9e1affa4004a78a2c1cb281e43214c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e6b4ff965b0a4ad2aeea893ca4a1c141":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"86a014f0261e442d8ee1e5c5f84c523f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a2af58d9ad08443a82619d199f228e30":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7f9ca7d348814f69a5e39095e5e9563f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6776ddbff7324c709aa0b648c43ef07d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"034be1968a6048a3a04cee4c7fb0c549":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}